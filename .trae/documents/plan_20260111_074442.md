# 问题分析

**用户需求**：处理易读错字.txt文件中成语部分的易读错字，将它们添加到现有的extracted_data.json文件中，暂时不考虑去重问题。

**成语格式分析**：
- 格式：成语名称 + 正确读音（错误读音）
- 例如：爱憎zēng（zèng）分明
- 这里的易错字是"憎"，正确读音是"zēng"，错误读音是"zèng"，相关词组是"爱憎分明"

**现有数据**：已经有一个包含310条易读错字数据的extracted_data.json文件。

# 解决方案

**修改提取脚本方案**：

1. **更新Python提取脚本**：
   - 添加处理成语格式的逻辑
   - 提取规则：
     - 从成语中提取包含正确读音和错误读音的字作为易错字
     - 提取括号前的正确读音
     - 提取括号中的错误读音
     - 保留完整成语作为相关词组
     - 保存原始文本，方便后期检查
   - 支持成语部分的格式解析

2. **提取步骤**：
   - 专门处理成语部分的数据
   - 暂时不考虑去重处理，直接提取所有成语数据
   - 保持与现有数据格式一致

3. **数据合并**：
   - 读取现有的extracted_data.json文件
   - 将新提取的成语数据添加到现有数据中
   - 暂时不进行去重处理
   - 保存更新后的数据到extracted_data.json文件

4. **验证和修改**：
   - 生成更新后的数据列表后，验证数据格式是否正确
   - 确保成语数据与现有数据格式一致
   - 检查是否有解析错误的条目

**技术优势**：
- 扩展现有脚本，避免重复开发
- 支持成语格式的解析，覆盖更多数据形式
- 数据合并功能，确保与现有数据的兼容性
- 暂时不考虑去重，简化处理逻辑
- 结构化存储，便于后续的修改和扩展

**预期成果**：
- 更新extracted_data.json文件，添加成语部分的易读错字数据
- 数据格式与现有数据一致，便于导入到每日一字的数据文件中
- 为每日一字提供更多的易读错字例子