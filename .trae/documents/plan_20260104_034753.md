# 易读错字数据优化计划

## 1. 问题分析
- **当前问题**：process-characters.js 脚本在选择词组时，只检查了是否包含目标字，但没有验证该字在词组中的读音是否与目标读音一致
- **数据结构优势**：
  - `idiom.json` 中的成语包含完整的拼音信息（每个字的拼音用空格分隔）
  - `word.json` 中的普通词语只有一个拼音，无法直接验证

## 2. 解决方案
- **优先使用成语**：成语数据有完整的拼音信息，可直接验证读音
- **词语处理**：对普通词语暂不使用，或根据常识判断后手动添加
- **修改脚本**：添加成语拼音验证逻辑，确保词组中目标字的读音与规定的正确读音一致

## 3. 实施步骤

### 3.1 修改 process-characters.js 脚本
1. **添加成语拼音验证功能**
   - 遍历成语的拼音，检查目标字在成语中的位置对应的拼音
   - 验证该拼音是否与目标读音一致
   - 只有读音一致的成语才能入选相关词组

2. **优化词语选择逻辑**
   - 优先从成语中选择相关词组
   - 成语不足时，根据常识手动添加符合读音要求的普通词语
   - 确保每个字至少有1个相关词组，最多4个

### 3.2 重新处理 50 个易读错字
1. **读取现有 50 个易读错字数据**
2. **逐一重新生成相关词组**
   - 对每个字，从成语库中查找符合读音要求的成语
   - 成语不足时，根据常识添加符合要求的普通词语
   - 确保所有词组中目标字的读音与规定的正确读音一致

### 3.3 更新数据文件
1. **更新 data-optimized.js**
   - 使用新生成的符合要求的相关词组替换原有词组
   - 确保其他属性（id、char、correctPronunciation、wrongPronunciations、explanation、errorReasonType、difficultyLevel）完整填充

2. **暂时不处理诗词文件**
   - 按照用户要求，先专注于易读错字数据文件的构建
   - 诗词文件的处理延后

## 4. 验证与检查
1. **语法验证**：运行 Node.js 语法检查，确保文件格式正确
2. **数据完整性**：确保每个字的所有属性都完整填充
3. **读音一致性**：验证每个词组中目标字的读音与规定的正确读音一致
4. **生成检查列表**：生成易读错字列表，包含字、正确读音、错误读音、相关词组，供用户检查

## 5. 预期交付物
1. **更新后的 data-optimized.js**：包含50个易读错字，每个字的相关词组都符合读音要求
2. **更新后的 process-characters.js**：添加了成语拼音验证功能
3. **易读错字检查列表**：方便用户检查易读错字数据