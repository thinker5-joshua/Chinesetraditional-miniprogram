# 重新完善每日一字数据文件优化方案

## 任务目标
逐项完善data-optimized.js中的每个字的数据，包括错误读音、关联词组、字典解释、错误原因分类和难度等级。

## 优化重点

### 1. 合并模型调用
- 将每个字的多轮模型调用（错误读音、关联词组、字典解释、错误原因分类、难度等级）合并为一轮调用
- 设计统一的prompt模板，一次性获取所有需要的信息
- 要求模型返回结构化数据，便于解析和处理

### 2. 详细记录和反馈
- 记录每个字的完整提示词
- 记录模型返回的原始结果
- 记录解析后的各字段数据
- 生成详细的处理日志，便于分析和调试

### 3. 分阶段实施
- 第一阶段：处理前5个字进行测试
- 分析测试结果，调整prompt和解析逻辑
- 第二阶段：根据测试结果决定是否处理全部字

## 技术实现方案

### 1. 统一Prompt设计
设计结构化prompt，包含以下内容：
- 汉字和正确读音
- 要求返回的字段：错误读音（1-3个）、关联词组（1-4个）、字典解释、错误原因分类、难度等级
- 要求返回格式：JSON格式，字段明确
- 错误原因分类规则说明
- 难度等级划分规则说明

### 2. 模型调用优化
- 使用DeepSeek API进行调用
- 设置合理的max_tokens和temperature
- 添加错误处理和重试机制
- 记录调用耗时和结果状态

### 3. 数据解析和处理
- 解析模型返回的JSON格式数据
- 验证数据完整性和合理性
- 处理异常情况和边界情况
- 生成详细的处理报告

### 4. 测试和验证
- 处理前5个字进行测试
- 分析测试结果，调整prompt和解析逻辑
- 验证数据格式和内容的正确性
- 生成测试报告，包含每个字的详细信息

## 预期输出
- 前5个字的详细处理报告，包含：
  - 原始提示词
  - 模型返回结果
  - 解析后的各字段数据
  - 处理状态和耗时
- 测试结果分析
- 基于测试结果的后续处理建议

## 技术要点
- Python脚本开发
- DeepSeek API集成
- 结构化prompt设计
- JSON解析和数据处理
- 详细日志记录
- 错误处理和异常管理